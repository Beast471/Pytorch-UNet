{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Unet_with_SEblock.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LuUbGrP0qeAL",
        "Em5XVMFqrFSo",
        "cfIYwcSyQ72H",
        "HqQjJ7BmwyRa",
        "ykHicJr9w3Sd",
        "XmrerTgWJYD6",
        "C0H_GF5OQYmF",
        "ydgvJC7dUZrh"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTI-E9neqh3M"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wM4hM9CqqMG"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9Sdh5IFkq_k"
      },
      "source": [
        "class Attention(nn.Module):   #it gives channel attention\n",
        "    def __init__(self, in_channels, reduced_dim):  #input_shape ---> output_shape\n",
        "        super(Attention, self).__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d(1), # C x H x W -> C x 1 x 1\n",
        "            nn.Conv3d(in_channels, reduced_dim, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv3d(reduced_dim, in_channels, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.se(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTm23AAugdYF"
      },
      "source": [
        "@torch.jit.script\n",
        "def autocrop(encoder_layer: torch.Tensor, decoder_layer: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Center-crops the encoder_layer to the size of the decoder_layer,\n",
        "    so that merging (concatenation) between levels/blocks is possible.\n",
        "    This is only necessary for input sizes != 2**n for 'same' padding and always required for 'valid' padding.\n",
        "    \"\"\"\n",
        "    if encoder_layer.shape[2:] != decoder_layer.shape[2:]:\n",
        "        ds = encoder_layer.shape[2:]\n",
        "        es = decoder_layer.shape[2:]\n",
        "        assert ds[0] >= es[0]\n",
        "        assert ds[1] >= es[1]\n",
        "        if encoder_layer.dim() == 4:  # 2D\n",
        "            encoder_layer = encoder_layer[\n",
        "                            :,\n",
        "                            :,\n",
        "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
        "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2)\n",
        "                            ]\n",
        "        elif encoder_layer.dim() == 5:  # 3D\n",
        "            assert ds[2] >= es[2]\n",
        "            encoder_layer = encoder_layer[\n",
        "                            :,\n",
        "                            :,\n",
        "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
        "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2),\n",
        "                            ((ds[2] - es[2]) // 2):((ds[2] + es[2]) // 2),\n",
        "                            ]\n",
        "    return encoder_layer, decoder_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDijGP-0gXgO"
      },
      "source": [
        "def conv_layer(dim: int):\n",
        "    if dim == 3:\n",
        "        return nn.Conv3d\n",
        "    elif dim == 2:\n",
        "        return nn.Conv2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mgc8LOgglq"
      },
      "source": [
        "def get_conv_layer(in_channels: int,\n",
        "                   out_channels: int,\n",
        "                   kernel_size: int = 3,\n",
        "                   stride: int = 1,\n",
        "                   padding: int = 1,\n",
        "                   bias: bool = True,\n",
        "                   dim: int = 2):\n",
        "    return conv_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                           bias=bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxQ2LuLoghyo"
      },
      "source": [
        "def conv_transpose_layer(dim: int):\n",
        "    if dim == 3:\n",
        "        return nn.ConvTranspose3d\n",
        "    elif dim == 2:\n",
        "        return nn.ConvTranspose2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udkg5Btago1T"
      },
      "source": [
        "def maxpool_layer(dim: int):\n",
        "    if dim == 3:\n",
        "        return nn.MaxPool3d\n",
        "    elif dim == 2:\n",
        "        return nn.MaxPool2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsX1EZAiglTf"
      },
      "source": [
        "def get_up_layer(in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 kernel_size: int = 2,\n",
        "                 stride: int = 2,\n",
        "                 dim: int = 3,\n",
        "                 up_mode: str = 'transposed',\n",
        "                 ):\n",
        "    if up_mode == 'transposed':\n",
        "        return conv_transpose_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
        "    else:\n",
        "        return nn.Upsample(scale_factor=2.0, mode=up_mode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ZRzitqgrZD"
      },
      "source": [
        "def get_maxpool_layer(kernel_size: int = 2,\n",
        "                      stride: int = 2,\n",
        "                      padding: int = 0,\n",
        "                      dim: int = 2):\n",
        "    return maxpool_layer(dim=dim)(kernel_size=kernel_size, stride=stride, padding=padding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuiw6GPgguYe"
      },
      "source": [
        "def get_activation(activation: str):\n",
        "    if activation == 'ReLU':\n",
        "        return nn.ReLU()\n",
        "    elif activation == 'leaky':\n",
        "        return nn.LeakyReLU(negative_slope=0.1)\n",
        "    elif activation == 'elu':\n",
        "        return nn.ELU()\n",
        "    elif activation == 'PReLU':\n",
        "        return nn.PReLU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_rvJs_1gxuU"
      },
      "source": [
        "def get_normalization(normalization: str,\n",
        "                      num_channels: int,\n",
        "                      dim: int):\n",
        "    if normalization == 'batch':\n",
        "        if dim == 3:\n",
        "            return nn.BatchNorm3d(num_channels)\n",
        "        elif dim == 2:\n",
        "            return nn.BatchNorm2d(num_channels)\n",
        "    elif normalization == 'instance':\n",
        "        if dim == 3:\n",
        "            return nn.InstanceNorm3d(num_channels)\n",
        "        elif dim == 2:\n",
        "            return nn.InstanceNorm2d(num_channels)\n",
        "    elif 'group' in normalization:\n",
        "        num_groups = int(normalization.partition('group')[-1])  # get the group size from string\n",
        "        return nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8hT481Eg0xS"
      },
      "source": [
        "class Concatenate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Concatenate, self).__init__()\n",
        "\n",
        "    def forward(self, layer_1, layer_2):\n",
        "        x = torch.cat((layer_1, layer_2), 1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c_0Ck7vkj75"
      },
      "source": [
        "class DownBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A helper Module that performs 2 Convolutions and 1 MaxPool.\n",
        "    An activation follows each convolution.\n",
        "    A normalization layer follows each convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 pooling: bool = True,\n",
        "                 activation: str = 'relu',\n",
        "                 normalization: str = None,\n",
        "                 dim: str = 2,\n",
        "                 conv_mode: str = 'same'):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.pooling = pooling\n",
        "        self.normalization = normalization\n",
        "        if conv_mode == 'same':\n",
        "            self.padding = 1\n",
        "        elif conv_mode == 'valid':\n",
        "            self.padding = 0\n",
        "        self.dim = dim\n",
        "        self.activation = activation\n",
        "\n",
        "        # conv layers\n",
        "        self.conv1 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
        "                                    bias=True, dim=self.dim)\n",
        "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
        "                                    bias=True, dim=self.dim)\n",
        "\n",
        "        # pooling layer\n",
        "        if self.pooling:\n",
        "            self.pool = get_maxpool_layer(kernel_size=2, stride=2, padding=0, dim=self.dim)\n",
        "\n",
        "        # activation layers\n",
        "        self.act1 = get_activation(self.activation)\n",
        "        self.act2 = get_activation(self.activation)\n",
        "\n",
        "        # normalization layers\n",
        "        if self.normalization:\n",
        "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
        "                                           dim=self.dim)\n",
        "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
        "                                           dim=self.dim)\n",
        "            \n",
        "        self.Attention = Attention(self.out_channels,16)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.conv1(x)  # convolution 1\n",
        "        y = self.act1(y)  # activation 1\n",
        "        if self.normalization:\n",
        "            y = self.norm1(y)  # normalization 1\n",
        "        y = self.conv2(y)  # convolution 2\n",
        "        y = self.act2(y)  # activation 2\n",
        "        if self.normalization:\n",
        "            y = self.norm2(y)  # normalization 2\n",
        "        \n",
        "        # y = self.Attention(y)\n",
        "\n",
        "        before_pooling = y"
        "        before_pooling = self.Attention(before_pooling)\n # save the outputs before the pooling operation\n",
        "        if self.pooling:\n",
        "            y = self.pool(y)  # pooling\n",
        "        return y, before_pooling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcFzAt0shQt6"
      },
      "source": [
        "class UpBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A helper Module that performs 2 Convolutions and 1 UpConvolution/Upsample.\n",
        "    An activation follows each convolution.\n",
        "    A normalization layer follows each convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels: int,\n",
        "                 out_channels: int,\n",
        "                 activation: str = 'relu',\n",
        "                 normalization: str = None,\n",
        "                 dim: int = 3,\n",
        "                 conv_mode: str = 'same',\n",
        "                 up_mode: str = 'transposed'\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalization = normalization\n",
        "        if conv_mode == 'same':\n",
        "            self.padding = 1\n",
        "        elif conv_mode == 'valid':\n",
        "            self.padding = 0\n",
        "        self.dim = dim\n",
        "        self.activation = activation\n",
        "        self.up_mode = up_mode\n",
        "\n",
        "        # upconvolution/upsample layer\n",
        "        self.up = get_up_layer(self.in_channels, self.out_channels, kernel_size=2, stride=2, dim=self.dim,\n",
        "                               up_mode=self.up_mode)\n",
        "\n",
        "        # conv layers\n",
        "        self.conv0 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
        "                                    bias=True, dim=self.dim)\n",
        "        self.conv1 = get_conv_layer(2 * self.out_channels, self.out_channels, kernel_size=3, stride=1,\n",
        "                                    padding=self.padding,\n",
        "                                    bias=True, dim=self.dim)\n",
        "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
        "                                    bias=True, dim=self.dim)\n",
        "\n",
        "        # activation layers\n",
        "        self.act0 = get_activation(self.activation)\n",
        "        self.act1 = get_activation(self.activation)\n",
        "        self.act2 = get_activation(self.activation)\n",
        "\n",
        "        # normalization layers\n",
        "        if self.normalization:\n",
        "            self.norm0 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
        "                                           dim=self.dim)\n",
        "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
        "                                           dim=self.dim)\n",
        "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
        "                                           dim=self.dim)\n",
        "\n",
        "        # concatenate layer\n",
        "        self.concat = Concatenate()\n",
        "\n",
        "    def forward(self, encoder_layer, decoder_layer):\n",
        "        \"\"\" Forward pass\n",
        "        Arguments:\n",
        "            encoder_layer: Tensor from the encoder pathway\n",
        "            decoder_layer: Tensor from the decoder pathway (to be up'd)\n",
        "        \"\"\"\n",
        "        \n",
        "        up_layer = self.up(decoder_layer)  # up-convolution/up-sampling\n",
        "        cropped_encoder_layer, dec_layer = autocrop(encoder_layer, up_layer)  # cropping\n",
        "\n",
        "        if self.up_mode != 'transposed':\n",
        "            # We need to reduce the channel dimension with a conv layer\n",
        "            up_layer = self.conv0(up_layer)  # convolution 0\n",
        "        up_layer = self.act0(up_layer)  # activation 0\n",
        "        if self.normalization:\n",
        "            up_layer = self.norm0(up_layer)  # normalization 0\n",
        "\n",
        "        merged_layer = self.concat(up_layer, cropped_encoder_layer)  # concatenation\n",
        "        y = self.conv1(merged_layer)  # convolution 1\n",
        "        y = self.act1(y)  # activation 1\n",
        "        if self.normalization:\n",
        "            y = self.norm1(y)  # normalization 1\n",
        "        y = self.conv2(y)  # convolution 2\n",
        "        y = self.act2(y)  # acivation 2\n",
        "        if self.normalization:\n",
        "            y = self.norm2(y)  # normalization 2\n",
        "        return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUHc_3zB8eLX"
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int = 1,\n",
        "                 out_channels: int = 2,\n",
        "                 n_blocks: int = 4,\n",
        "                 start_filters: int = 32,\n",
        "                 activation: str = 'relu',\n",
        "                 normalization: str = 'batch',\n",
        "                 conv_mode: str = 'same',\n",
        "                 dim: int = 2,\n",
        "                 up_mode: str = 'transposed'\n",
        "                 ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.n_blocks = n_blocks\n",
        "        self.start_filters = start_filters\n",
        "        self.activation = activation\n",
        "        self.normalization = normalization\n",
        "        self.conv_mode = conv_mode\n",
        "        self.dim = dim\n",
        "        self.up_mode = up_mode\n",
        "\n",
        "        self.down_blocks = []\n",
        "        self.up_blocks = []\n",
        "\n",
        "        # create encoder path\n",
        "        for i in range(self.n_blocks):\n",
        "            num_filters_in = self.in_channels if i == 0 else num_filters_out\n",
        "            num_filters_out = self.start_filters * (2 ** i)\n",
        "            pooling = True if i < self.n_blocks - 1 else False\n",
        "\n",
        "            down_block = DownBlock(in_channels=num_filters_in,\n",
        "                                   out_channels=num_filters_out,\n",
        "                                   pooling=pooling,\n",
        "                                   activation=self.activation,\n",
        "                                   normalization=self.normalization,\n",
        "                                   conv_mode=self.conv_mode,\n",
        "                                   dim=self.dim)\n",
        "\n",
        "            self.down_blocks.append(down_block)\n",
        "\n",
        "        # create decoder path (requires only n_blocks-1 blocks)\n",
        "        for i in range(n_blocks - 1):\n",
        "            num_filters_in = num_filters_out\n",
        "            num_filters_out = num_filters_in // 2\n",
        "\n",
        "            up_block = UpBlock(in_channels=num_filters_in,\n",
        "                               out_channels=num_filters_out,\n",
        "                               activation=self.activation,\n",
        "                               normalization=self.normalization,\n",
        "                               conv_mode=self.conv_mode,\n",
        "                               dim=self.dim,\n",
        "                               up_mode=self.up_mode)\n",
        "\n",
        "            self.up_blocks.append(up_block)\n",
        "\n",
        "        # final convolution\n",
        "        self.conv_final = get_conv_layer(num_filters_out, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
        "                                         bias=True, dim=self.dim)\n",
        "\n",
        "        # add the list of modules to current module\n",
        "        self.down_blocks = nn.ModuleList(self.down_blocks)\n",
        "        self.up_blocks = nn.ModuleList(self.up_blocks)\n",
        "\n",
        "        # initialize the weights\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    @staticmethod\n",
        "    def weight_init(module, method, **kwargs):\n",
        "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
        "            method(module.weight, **kwargs)  # weights\n",
        "\n",
        "    @staticmethod\n",
        "    def bias_init(module, method, **kwargs):\n",
        "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
        "            method(module.bias, **kwargs)  # bias\n",
        "\n",
        "    def initialize_parameters(self,\n",
        "                              method_weights=nn.init.kaiming_uniform_,\n",
        "                              method_bias=nn.init.zeros_,\n",
        "                              kwargs_weights={},\n",
        "                              kwargs_bias={}\n",
        "                              ):\n",
        "        for module in self.modules():\n",
        "            self.weight_init(module, method_weights, **kwargs_weights)  # initialize weights\n",
        "            self.bias_init(module, method_bias, **kwargs_bias)  # initialize bias\n",
        "\n",
        "    def forward(self, x: torch.tensor):\n",
        "        encoder_output = []\n",
        "\n",
        "        # Encoder pathway\n",
        "        for module in self.down_blocks:\n",
        "            x, before_pooling = module(x)\n",
        "            encoder_output.append(before_pooling)\n",
        "\n",
        "        # Decoder pathway\n",
        "        for i, module in enumerate(self.up_blocks):\n",
        "            before_pool = encoder_output[-(i + 2)]\n",
        "            x = module(before_pool, x)\n",
        "\n",
        "        x = self.conv_final(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsCySTvDltDa"
      },
      "source": [
        "model = UNet(in_channels=3,\n",
        "             out_channels=4,\n",
        "             n_blocks=4,\n",
        "             start_filters=32,\n",
        "             activation='ReLU',\n",
        "             normalization='batch',\n",
        "             conv_mode='same',\n",
        "             dim=3).to(device)\n",
        "\n",
        "x = torch.randn(size=(6, 3, 128, 128, 48), dtype=torch.float32)\n",
        "with torch.no_grad():\n",
        "    out = model(x)\n",
        "\n",
        "print(f'Out: {out.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
